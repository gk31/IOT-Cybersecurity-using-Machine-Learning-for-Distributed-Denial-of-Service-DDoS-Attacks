{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PRb7dEzfrUo2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b01e8f07-e134-45b6-a864-2151291b8bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./drive/My\\ Drive"
      ],
      "metadata": {
        "id": "yCL5kywVrVMx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b5b6d02-11cf-4b05-e2a2-81edfbc36b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: './drive/My Drive'\n",
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./SAP/03-11"
      ],
      "metadata": {
        "id": "LjzJWOnXcRUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "fields= ['Max Packet Length','Fwd Packet Length Max','Fwd Packet Length Min','Average Packet Size','Min Packet Length','Label','Fwd Packets/s','min_seg_size_forward','Protocol','Fwd Header Length','Fwd Header Length']\n",
        "df = pd.read_csv(\"NetBIOS.csv\",skipinitialspace=True, usecols = fields)\n",
        "df2 = pd.read_csv(\"LDAP.csv\",skipinitialspace=True, usecols = fields)\n",
        "df = df[df.Label != 'BENIGN']\n",
        "df2= df2[df2.Label != 'BENIGN']\n",
        "#df = pd.read_csv('data.csv', skipinitialspace=True, usecols=fields)"
      ],
      "metadata": {
        "id": "kqeM8pgNcKGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()"
      ],
      "metadata": {
        "id": "_azg_in82pqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].unique()"
      ],
      "metadata": {
        "id": "_e1YY8LOrVYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df, df2]\n",
        "df = pd.concat(frames)\n",
        "df.dropna()\n",
        "df['Label'].value_counts()\n"
      ],
      "metadata": {
        "id": "9Lakh24V6x12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_net = df[df.Label=='NetBIOS'].sample(n = 1905191)\n",
        "df_net['Label'].value_counts()"
      ],
      "metadata": {
        "id": "KKwahAj87zIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ldap = df[df.Label=='LDAP'].sample(n = 1905191)\n",
        "df_ldap['Label'].value_counts()"
      ],
      "metadata": {
        "id": "OiBAhm8B-Itz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames=[df_net,df_ldap]\n",
        "df=pd.concat(frames)"
      ],
      "metadata": {
        "id": "FWtDTM7g-W9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'].value_counts()\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "UflxHqh5-idf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(df['Label'])"
      ],
      "metadata": {
        "id": "QG74AqsjuBTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df[['Max Packet Length','Fwd Packet Length Max','Fwd Packet Length Min','Average Packet Size','Min Packet Length','Fwd Packets/s','min_seg_size_forward','Protocol','Fwd Header Length']]"
      ],
      "metadata": {
        "id": "jP_nvRQWr3l5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1234)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "gqZUjBv9rVbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision tree Classifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf_DT = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "#cross_val_score(clf, X_train, y_train, cv=10)"
      ],
      "metadata": {
        "id": "2VgD6DLdrVdQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_DT= clf_DT.fit(X_train,y_train)\n",
        "y_pred = clf_DT.predict(X_test)"
      ],
      "metadata": {
        "id": "O0ip8uG8vYLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "KkiZi8l5v2U-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XuZkpnxUwlPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "9J9NqIUYydnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "print('Accuracy = ', metrics.accuracy_score(y_test, y_pred)*100)\n",
        "print(\"Confusion Matrix =\\n\", metrics.confusion_matrix(y_test, y_pred, labels=None,\n",
        "                                              sample_weight=None))\n",
        "print(\"Recall =\", metrics.recall_score(y_test, y_pred, labels=None,\n",
        "                                             pos_label=1, average='weighted',\n",
        "                                             sample_weight=None))\n",
        "print(\"Classification Report =\\n\", metrics.classification_report(y_test, y_pred,\n",
        "                                                                 labels=None,\n",
        "                                                                 target_names=None,\n",
        "                                                                 sample_weight=None,\n",
        "                                                                 digits=2,\n",
        "                                                                 output_dict=False))\n",
        "\n",
        "print(\"F1 Score = \",f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "5asfdkOmz1or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RandomForest Classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf = RandomForestClassifier(max_depth=3, random_state=0)\n",
        "\n",
        "#cross_val_score(clf, X_train, y_train, cv=10)"
      ],
      "metadata": {
        "id": "DM1uhVfv5Pbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "8yRmg6B25g-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "3k_Ap8ad5lKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SnWlIgK_8CFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "Otsvcirj8Ggd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "print('Accuracy = ', metrics.accuracy_score(y_test, y_pred)*100)\n",
        "print(\"Confusion Matrix =\\n\", metrics.confusion_matrix(y_test, y_pred, labels=None,\n",
        "                                              sample_weight=None))\n",
        "print(\"Recall =\", metrics.recall_score(y_test, y_pred, labels=None,\n",
        "                                             pos_label=1, average='weighted',\n",
        "                                             sample_weight=None))\n",
        "print(\"Classification Report =\\n\", metrics.classification_report(y_test, y_pred,\n",
        "                                                                 labels=None,\n",
        "                                                                 target_names=None,\n",
        "                                                                 sample_weight=None,\n",
        "                                                                 digits=2,\n",
        "                                                                 output_dict=False))\n",
        "\n",
        "print(\"F1 Score = \",f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "rp4nnzbF8P_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "3GJvliN68Wtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = clf.fit(X_train,y_train)\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "8-5D0BdT8xX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "metadata": {
        "id": "bysXYD3V9HzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "plot_confusion_matrix(clf, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HE5iKHCa9ICa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "l037C0Md9IFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "print('Accuracy = ', metrics.accuracy_score(y_test, y_pred)*100)\n",
        "print(\"Confusion Matrix =\\n\", metrics.confusion_matrix(y_test, y_pred, labels=None,\n",
        "                                              sample_weight=None))\n",
        "print(\"Recall =\", metrics.recall_score(y_test, y_pred, labels=None,\n",
        "                                             pos_label=1, average='weighted',\n",
        "                                             sample_weight=None))\n",
        "print(\"Classification Report =\\n\", metrics.classification_report(y_test, y_pred,\n",
        "                                                                 labels=None,\n",
        "                                                                 target_names=None,\n",
        "                                                                 sample_weight=None,\n",
        "                                                                 digits=2,\n",
        "                                                                 output_dict=False))\n",
        "\n",
        "print(\"F1 Score = \",f1_score(y_test, y_pred, average='macro'))"
      ],
      "metadata": {
        "id": "a0DY77fv9IL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}